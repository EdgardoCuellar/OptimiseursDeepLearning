# Les algorithmes d'optimisation pour les réseaux de neurones pour la reconnaissance de texte manuscrit
## Tests de cinq algorithmes d'optimisation avec Pytorch et cuda, et le jeu de données MNIST

L'optimisation est la base du deep learning, l'optimisation faisant référence à la minimisation du loss d'un modèle, le loss nous indiquant l'efficacité de notre modèle.
Dans cet article, nous analyserons les différents algorithmes d'optimisations permettant d'améliorer l'efficacité de notre modèle de reconnaissance de text manuscrit avec le jeu de données MNIST. Les cinq principaux algorithmes étudiés ici seront le Stochastic Gradient Descent, Mini Batch, SGD avec momentum, et l'Adaptive Gradient Descent, et le RMSProp.

### Libs:
- Pytorch
- Matplotlib
- Numpy

### Utilisation
Pour lancer la creation d'un modèle:
```bash
  python ./main.py
```

Pour le plot recapitulatif des temps
```bash
  python ./basics.py
```
    
