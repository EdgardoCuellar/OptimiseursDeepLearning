Stochastic Gradient Descent
0 Test set: Avg. loss: 2.3316, Accuracy: 1137/10000 (11%)
1 Test set: Avg. loss: 0.2211, Accuracy: 9361/10000 (94%)
2 Test set: Avg. loss: 0.2746, Accuracy: 9224/10000 (92%)
3 Test set: Avg. loss: 0.2427, Accuracy: 9360/10000 (94%)
4 Test set: Avg. loss: 0.2604, Accuracy: 9218/10000 (92%)
5 Test set: Avg. loss: 0.2332, Accuracy: 9346/10000 (93%)
6 Test set: Avg. loss: 0.2126, Accuracy: 9420/10000 (94%)
7 Test set: Avg. loss: 0.2774, Accuracy: 9141/10000 (91%)
8 Test set: Avg. loss: 0.3025, Accuracy: 9131/10000 (91%)
9 Test set: Avg. loss: 0.2952, Accuracy: 9213/10000 (92%)
10 Test set: Avg. loss: 0.2424, Accuracy: 9339/10000 (93%)

Mini Batch
0 Test set: Avg. loss: 2.3091, Accuracy: 962/10000 (10%)
1 Test set: Avg. loss: 0.3618, Accuracy: 8971/10000 (90%)
2 Test set: Avg. loss: 0.1781, Accuracy: 9476/10000 (95%)
3 Test set: Avg. loss: 0.1623, Accuracy: 9444/10000 (94%)
4 Test set: Avg. loss: 0.1140, Accuracy: 9648/10000 (96%)
5 Test set: Avg. loss: 0.0995, Accuracy: 9677/10000 (97%)
6 Test set: Avg. loss: 0.0774, Accuracy: 9742/10000 (97%)
7 Test set: Avg. loss: 0.0668, Accuracy: 9791/10000 (98%)
8 Test set: Avg. loss: 0.0517, Accuracy: 9828/10000 (98%)
9 Test set: Avg. loss: 0.0487, Accuracy: 9860/10000 (99%)
10 Test set: Avg. loss: 0.0515, Accuracy: 9835/10000 (98%)

SGD avec momentum
0 Test set: Avg. loss: 2.3097, Accuracy: 987/10000 (10%)
1 Test set: Avg. loss: 0.4034, Accuracy: 8629/10000 (86%)
2 Test set: Avg. loss: 0.1490, Accuracy: 9561/10000 (96%)
3 Test set: Avg. loss: 0.1464, Accuracy: 9560/10000 (96%)
4 Test set: Avg. loss: 0.1105, Accuracy: 9658/10000 (97%)
5 Test set: Avg. loss: 0.0844, Accuracy: 9746/10000 (97%)
6 Test set: Avg. loss: 0.0660, Accuracy: 9784/10000 (98%)
7 Test set: Avg. loss: 0.0637, Accuracy: 9797/10000 (98%)
8 Test set: Avg. loss: 0.0619, Accuracy: 9787/10000 (98%)
9 Test set: Avg. loss: 0.0553, Accuracy: 9837/10000 (98%)
10 Test set: Avg. loss: 0.0687, Accuracy: 9783/10000 (98%)

Adaptive Gradient Descent
0 Test set: Avg. loss: 2.3013, Accuracy: 1322/10000 (13%)
1 Test set: Avg. loss: 0.2481, Accuracy: 9304/10000 (93%)
2 Test set: Avg. loss: 0.1829, Accuracy: 9491/10000 (95%)
3 Test set: Avg. loss: 0.1437, Accuracy: 9580/10000 (96%)
4 Test set: Avg. loss: 0.1288, Accuracy: 9624/10000 (96%)
5 Test set: Avg. loss: 0.1168, Accuracy: 9674/10000 (97%)
6 Test set: Avg. loss: 0.1075, Accuracy: 9679/10000 (97%)
7 Test set: Avg. loss: 0.0978, Accuracy: 9697/10000 (97%)
8 Test set: Avg. loss: 0.0928, Accuracy: 9718/10000 (97%)
9 Test set: Avg. loss: 0.0906, Accuracy: 9704/10000 (97%)
10 Test set: Avg. loss: 0.0812, Accuracy: 9755/10000 (98%)

RMSProp
0 Test set: Avg. loss: 2.3090, Accuracy: 1372/10000 (14%)
1 Test set: Avg. loss: 0.2000, Accuracy: 9392/10000 (94%)
2 Test set: Avg. loss: 0.1456, Accuracy: 9525/10000 (95%)
3 Test set: Avg. loss: 0.1111, Accuracy: 9639/10000 (96%)
4 Test set: Avg. loss: 0.1023, Accuracy: 9671/10000 (97%)
5 Test set: Avg. loss: 0.0836, Accuracy: 9734/10000 (97%)
6 Test set: Avg. loss: 0.0739, Accuracy: 9771/10000 (98%)
7 Test set: Avg. loss: 0.0621, Accuracy: 9800/10000 (98%)
8 Test set: Avg. loss: 0.0630, Accuracy: 9785/10000 (98%)
9 Test set: Avg. loss: 0.0521, Accuracy: 9834/10000 (98%)
10 Test set: Avg. loss: 0.0466, Accuracy: 9858/10000 (99%)
[228.38012170791626, 47.80546689033508, 50.01236081123352, 52.6740403175354, 53.74828386306763]
Stochastic Gradient Descent
[2.3316362548828127, 0.2210946304321289, 0.27457635192871094, 0.2427280014038086, 0.2604205047607422, 0.23319992523193359, 0.21264894104003906, 0.27741934204101565, 0.30254359436035155, 0.29524080200195313, 0.24242805938720702]
Mini Batch
[2.3090586181640624, 0.3618389770507813, 0.17808472290039062, 0.16234560089111327, 0.11397349090576171, 0.09952167129516601, 0.07740614585876465, 0.06677475852966308, 0.05173997077941894, 0.04866970024108887, 0.0515456657409668]
SGD avec momentum
[2.30970029296875, 0.4033932525634766, 0.14899457397460938, 0.14644386825561523, 0.11049604034423828, 0.08441290817260742, 0.06595812530517578, 0.06374572792053222, 0.06193403854370117, 0.055312974166870116, 0.06872424545288086]
Adaptive Gradient Descent
[2.3013293212890624, 0.24805077209472656, 0.1828796585083008, 0.1437275436401367, 0.12875071029663085, 0.11683991622924805, 0.1075213752746582, 0.09782128067016602, 0.09282285995483398, 0.09057925987243652, 0.08121657485961914]
RMSProp
[2.3090149658203125, 0.2000106170654297, 0.145571475982666, 0.11106752319335937, 0.10229430160522461, 0.08355501403808593, 0.0738671543121338, 0.062104215240478516, 0.06303509025573731, 0.05207168884277344, 0.04663689956665039]