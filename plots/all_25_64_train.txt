Stochastic Gradient Descent
0 Test set: Avg. loss: 2.3304, Accuracy: 6747/60000 (11%)
1 Test set: Avg. loss: 0.2200, Accuracy: 56521/60000 (94%)
2 Test set: Avg. loss: 0.4294, Accuracy: 53089/60000 (88%)
3 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
4 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
5 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
6 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
7 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
8 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
9 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
10 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
11 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
12 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
13 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
14 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
15 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
16 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
17 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
18 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
19 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
20 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
21 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
22 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
23 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
24 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)
25 Test set: Avg. loss: nan, Accuracy: 5923/60000 (10%)

Mini Batch
0 Test set: Avg. loss: 2.3218, Accuracy: 3567/60000 (6%)
1 Test set: Avg. loss: 0.0949, Accuracy: 58279/60000 (97%)
2 Test set: Avg. loss: 0.0717, Accuracy: 58689/60000 (98%)
3 Test set: Avg. loss: 0.0672, Accuracy: 58779/60000 (98%)
4 Test set: Avg. loss: 0.0531, Accuracy: 59048/60000 (98%)
5 Test set: Avg. loss: 0.0679, Accuracy: 58765/60000 (98%)
6 Test set: Avg. loss: 0.0452, Accuracy: 59192/60000 (99%)
7 Test set: Avg. loss: 0.0494, Accuracy: 59127/60000 (99%)
8 Test set: Avg. loss: 0.0410, Accuracy: 59283/60000 (99%)
9 Test set: Avg. loss: 0.0462, Accuracy: 59209/60000 (99%)
10 Test set: Avg. loss: 0.0410, Accuracy: 59253/60000 (99%)
11 Test set: Avg. loss: 0.0360, Accuracy: 59368/60000 (99%)
12 Test set: Avg. loss: 0.0435, Accuracy: 59196/60000 (99%)
13 Test set: Avg. loss: 0.0359, Accuracy: 59359/60000 (99%)
14 Test set: Avg. loss: 0.0364, Accuracy: 59325/60000 (99%)
15 Test set: Avg. loss: 0.0381, Accuracy: 59292/60000 (99%)
16 Test set: Avg. loss: 0.0319, Accuracy: 59415/60000 (99%)
17 Test set: Avg. loss: 0.0341, Accuracy: 59375/60000 (99%)
18 Test set: Avg. loss: 0.0298, Accuracy: 59471/60000 (99%)
19 Test set: Avg. loss: 0.0330, Accuracy: 59424/60000 (99%)
20 Test set: Avg. loss: 0.0289, Accuracy: 59454/60000 (99%)
21 Test set: Avg. loss: 0.0300, Accuracy: 59468/60000 (99%)
22 Test set: Avg. loss: 0.0284, Accuracy: 59474/60000 (99%)
23 Test set: Avg. loss: 0.0278, Accuracy: 59506/60000 (99%)
24 Test set: Avg. loss: 0.0304, Accuracy: 59433/60000 (99%)
25 Test set: Avg. loss: 0.0300, Accuracy: 59472/60000 (99%)

SGD avec momentum
0 Test set: Avg. loss: 2.3225, Accuracy: 5085/60000 (8%)
1 Test set: Avg. loss: 0.1101, Accuracy: 57982/60000 (97%)
2 Test set: Avg. loss: 0.0785, Accuracy: 58553/60000 (98%)
3 Test set: Avg. loss: 0.0614, Accuracy: 58899/60000 (98%)
4 Test set: Avg. loss: 0.0695, Accuracy: 58807/60000 (98%)
5 Test set: Avg. loss: 0.0617, Accuracy: 58921/60000 (98%)
6 Test set: Avg. loss: 0.0519, Accuracy: 59075/60000 (98%)
7 Test set: Avg. loss: 0.0676, Accuracy: 58726/60000 (98%)
8 Test set: Avg. loss: 0.0447, Accuracy: 59171/60000 (99%)
9 Test set: Avg. loss: 0.0516, Accuracy: 59050/60000 (98%)
10 Test set: Avg. loss: 0.0446, Accuracy: 59188/60000 (99%)
11 Test set: Avg. loss: 0.0584, Accuracy: 58962/60000 (98%)
12 Test set: Avg. loss: 0.0512, Accuracy: 59003/60000 (98%)
13 Test set: Avg. loss: 0.0457, Accuracy: 59174/60000 (99%)
14 Test set: Avg. loss: 0.0433, Accuracy: 59202/60000 (99%)
15 Test set: Avg. loss: 0.0475, Accuracy: 59079/60000 (98%)
16 Test set: Avg. loss: 0.0377, Accuracy: 59326/60000 (99%)
17 Test set: Avg. loss: 0.0444, Accuracy: 59171/60000 (99%)
18 Test set: Avg. loss: 0.0468, Accuracy: 59140/60000 (99%)
19 Test set: Avg. loss: 0.0380, Accuracy: 59305/60000 (99%)
20 Test set: Avg. loss: 0.0366, Accuracy: 59342/60000 (99%)
21 Test set: Avg. loss: 0.0401, Accuracy: 59259/60000 (99%)
22 Test set: Avg. loss: 0.0383, Accuracy: 59323/60000 (99%)
23 Test set: Avg. loss: 0.0372, Accuracy: 59300/60000 (99%)
24 Test set: Avg. loss: 0.0377, Accuracy: 59319/60000 (99%)
25 Test set: Avg. loss: 0.0392, Accuracy: 59321/60000 (99%)

Adaptive Gradient Descent
0 Test set: Avg. loss: 2.3122, Accuracy: 5336/60000 (9%)
1 Test set: Avg. loss: 0.1403, Accuracy: 57507/60000 (96%)
2 Test set: Avg. loss: 0.1127, Accuracy: 57969/60000 (97%)
3 Test set: Avg. loss: 0.0995, Accuracy: 58172/60000 (97%)
4 Test set: Avg. loss: 0.0906, Accuracy: 58331/60000 (97%)
5 Test set: Avg. loss: 0.0853, Accuracy: 58430/60000 (97%)
6 Test set: Avg. loss: 0.0794, Accuracy: 58565/60000 (98%)
7 Test set: Avg. loss: 0.0756, Accuracy: 58598/60000 (98%)
8 Test set: Avg. loss: 0.0734, Accuracy: 58668/60000 (98%)
9 Test set: Avg. loss: 0.0714, Accuracy: 58696/60000 (98%)
10 Test set: Avg. loss: 0.0691, Accuracy: 58756/60000 (98%)
11 Test set: Avg. loss: 0.0675, Accuracy: 58755/60000 (98%)
12 Test set: Avg. loss: 0.0646, Accuracy: 58810/60000 (98%)
13 Test set: Avg. loss: 0.0634, Accuracy: 58852/60000 (98%)
14 Test set: Avg. loss: 0.0619, Accuracy: 58850/60000 (98%)
15 Test set: Avg. loss: 0.0610, Accuracy: 58883/60000 (98%)
16 Test set: Avg. loss: 0.0599, Accuracy: 58894/60000 (98%)
17 Test set: Avg. loss: 0.0589, Accuracy: 58906/60000 (98%)
18 Test set: Avg. loss: 0.0583, Accuracy: 58919/60000 (98%)
19 Test set: Avg. loss: 0.0567, Accuracy: 58977/60000 (98%)
20 Test set: Avg. loss: 0.0558, Accuracy: 58982/60000 (98%)
21 Test set: Avg. loss: 0.0548, Accuracy: 59001/60000 (98%)
22 Test set: Avg. loss: 0.0542, Accuracy: 58993/60000 (98%)
23 Test set: Avg. loss: 0.0540, Accuracy: 59016/60000 (98%)
24 Test set: Avg. loss: 0.0525, Accuracy: 59040/60000 (98%)
25 Test set: Avg. loss: 0.0521, Accuracy: 59055/60000 (98%)

RMSProp
0 Test set: Avg. loss: 2.3298, Accuracy: 5224/60000 (9%)
1 Test set: Avg. loss: 0.1093, Accuracy: 58051/60000 (97%)
2 Test set: Avg. loss: 0.0834, Accuracy: 58477/60000 (97%)
3 Test set: Avg. loss: 0.0674, Accuracy: 58739/60000 (98%)
4 Test set: Avg. loss: 0.0596, Accuracy: 58914/60000 (98%)
5 Test set: Avg. loss: 0.0568, Accuracy: 58961/60000 (98%)
6 Test set: Avg. loss: 0.0506, Accuracy: 59079/60000 (98%)
7 Test set: Avg. loss: 0.0512, Accuracy: 59067/60000 (98%)
8 Test set: Avg. loss: 0.0441, Accuracy: 59181/60000 (99%)
9 Test set: Avg. loss: 0.0441, Accuracy: 59191/60000 (99%)
10 Test set: Avg. loss: 0.0406, Accuracy: 59255/60000 (99%)
11 Test set: Avg. loss: 0.0409, Accuracy: 59231/60000 (99%)
12 Test set: Avg. loss: 0.0419, Accuracy: 59231/60000 (99%)
13 Test set: Avg. loss: 0.0370, Accuracy: 59274/60000 (99%)
14 Test set: Avg. loss: 0.0371, Accuracy: 59283/60000 (99%)
15 Test set: Avg. loss: 0.0362, Accuracy: 59344/60000 (99%)
16 Test set: Avg. loss: 0.0344, Accuracy: 59366/60000 (99%)
17 Test set: Avg. loss: 0.0323, Accuracy: 59377/60000 (99%)
18 Test set: Avg. loss: 0.0332, Accuracy: 59375/60000 (99%)
19 Test set: Avg. loss: 0.0319, Accuracy: 59364/60000 (99%)
20 Test set: Avg. loss: 0.0291, Accuracy: 59442/60000 (99%)
21 Test set: Avg. loss: 0.0297, Accuracy: 59469/60000 (99%)
22 Test set: Avg. loss: 0.0297, Accuracy: 59444/60000 (99%)
23 Test set: Avg. loss: 0.0325, Accuracy: 59393/60000 (99%)
24 Test set: Avg. loss: 0.0304, Accuracy: 59426/60000 (99%)
25 Test set: Avg. loss: 0.0301, Accuracy: 59435/60000 (99%)
[3374.1272325515747, 677.444916009903, 685.7470302581787, 690.5538585186005, 692.8289818763733]
Stochastic Gradient Descent
[2.3304083821614583, 0.21996390686035155, 0.4293910502115885, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]
Mini Batch
[2.3217646443684896, 0.09492527192433675, 0.07171505889892578, 0.06717009874979656, 0.05305491075515747, 0.06793911221822103, 0.04516933479309082, 0.04943166669209798, 0.04104425541559855, 0.046178561210632324, 0.04101807975769043, 0.036044664192199705, 0.04346699775060018, 0.035860912958780924, 0.036445577716827396, 0.03806593949000041, 0.03193910352389018, 0.03408471666971843, 0.029822089076042176, 0.033028352737426755, 0.02893085757891337, 0.030015535847345988, 0.028443029514948526, 0.027754219992955527, 0.03041545737584432, 0.03004975134531657]
SGD avec momentum
[2.322528063964844, 0.11007214266459148, 0.07854934711456299, 0.06141566092173258, 0.06947767556508382, 0.061732992680867516, 0.05190356413523356, 0.0675880402882894, 0.04470602814356486, 0.05162897510528564, 0.04460234514872233, 0.05844057426452637, 0.051246580378214515, 0.045671581172943114, 0.043294468275705975, 0.04754441375732422, 0.03765268529256185, 0.04440018580754598, 0.04679624554316203, 0.038035198656717936, 0.036626767412821455, 0.040127810700734456, 0.038262115828196205, 0.03722455835342407, 0.037677696164449055, 0.039171064599355064]
Adaptive Gradient Descent
[2.3122464152018227, 0.14027118682861328, 0.11273268178304037, 0.09951093940734863, 0.09063290195465087, 0.0852580727259318, 0.07936150150299072, 0.07561513678232828, 0.07338198337554931, 0.07136038233439128, 0.06912621618906657, 0.06747038447062174, 0.0646441385269165, 0.0633716786066691, 0.06194459056854248, 0.0609653507232666, 0.05994546089172363, 0.058914595794677733, 0.058289068603515626, 0.056690915298461916, 0.055803937721252445, 0.054770070679982505, 0.05422270828882853, 0.054029959932963056, 0.052490236727396646, 
0.05211797275543213]
RMSProp
[2.329798836263021, 0.10929375190734864, 0.08340656121571859, 0.06742410354614257, 0.059555312887827554, 0.05684994004567464, 0.0505933198928833, 0.05124403060277303, 0.044104921181996666, 0.04406839580535889, 0.04061631619135539, 0.0408896577835083, 0.04189724257787069, 0.03702146991093953, 0.03705729983647665, 0.03617142712275187, 0.034404801909128827, 0.03225982917149862, 0.03323821331659953, 0.03187700812021891, 0.02914494605064392, 0.02965259601275126, 0.029725535424550375, 0.03248520663579305, 0.0304282323996226, 0.030069408257802327]