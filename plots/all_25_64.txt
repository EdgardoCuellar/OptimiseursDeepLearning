Stochastic Gradient Descent
0 Test set: Avg. loss: 2.3316, Accuracy: 1137/10000 (11%)
1 Test set: Avg. loss: 0.2211, Accuracy: 9361/10000 (94%)
2 Test set: Avg. loss: 0.2746, Accuracy: 9224/10000 (92%)
3 Test set: Avg. loss: 0.2427, Accuracy: 9360/10000 (94%)
4 Test set: Avg. loss: 0.2604, Accuracy: 9218/10000 (92%)
5 Test set: Avg. loss: 0.2332, Accuracy: 9346/10000 (93%)
6 Test set: Avg. loss: 0.2126, Accuracy: 9420/10000 (94%)
7 Test set: Avg. loss: 0.2774, Accuracy: 9141/10000 (91%)
8 Test set: Avg. loss: 0.3025, Accuracy: 9131/10000 (91%)
9 Test set: Avg. loss: 0.2952, Accuracy: 9213/10000 (92%)
10 Test set: Avg. loss: 0.2424, Accuracy: 9339/10000 (93%)
11 Test set: Avg. loss: 0.3675, Accuracy: 9005/10000 (90%)
12 Test set: Avg. loss: 0.3578, Accuracy: 8966/10000 (90%)
13 Test set: Avg. loss: 0.4306, Accuracy: 8801/10000 (88%)
14 Test set: Avg. loss: 0.7414, Accuracy: 7745/10000 (77%)
15 Test set: Avg. loss: 0.7134, Accuracy: 8064/10000 (81%)
16 Test set: Avg. loss: 0.6723, Accuracy: 7906/10000 (79%)
17 Test set: Avg. loss: 1.9792, Accuracy: 2460/10000 (25%)
18 Test set: Avg. loss: 1.6472, Accuracy: 4137/10000 (41%)
19 Test set: Avg. loss: 1.3822, Accuracy: 5043/10000 (50%)
20 Test set: Avg. loss: 0.8511, Accuracy: 7337/10000 (73%)
21 Test set: Avg. loss: 0.7261, Accuracy: 7726/10000 (77%)
22 Test set: Avg. loss: 1.0056, Accuracy: 6962/10000 (70%)
23 Test set: Avg. loss: 1.0643, Accuracy: 6866/10000 (69%)
24 Test set: Avg. loss: 0.5359, Accuracy: 8463/10000 (85%)
25 Test set: Avg. loss: 0.8839, Accuracy: 7227/10000 (72%)

Mini Batch
0 Test set: Avg. loss: 2.3209, Accuracy: 600/10000 (6%)
1 Test set: Avg. loss: 0.2702, Accuracy: 9195/10000 (92%)
2 Test set: Avg. loss: 0.1730, Accuracy: 9469/10000 (95%)
3 Test set: Avg. loss: 0.1389, Accuracy: 9549/10000 (95%)
4 Test set: Avg. loss: 0.1212, Accuracy: 9598/10000 (96%)
5 Test set: Avg. loss: 0.0894, Accuracy: 9717/10000 (97%)
6 Test set: Avg. loss: 0.1167, Accuracy: 9629/10000 (96%)
7 Test set: Avg. loss: 0.0663, Accuracy: 9788/10000 (98%)
8 Test set: Avg. loss: 0.0603, Accuracy: 9819/10000 (98%)
9 Test set: Avg. loss: 0.0514, Accuracy: 9838/10000 (98%)
10 Test set: Avg. loss: 0.0494, Accuracy: 9845/10000 (98%)
11 Test set: Avg. loss: 0.0533, Accuracy: 9824/10000 (98%)
12 Test set: Avg. loss: 0.0454, Accuracy: 9874/10000 (99%)
13 Test set: Avg. loss: 0.0399, Accuracy: 9885/10000 (99%)
14 Test set: Avg. loss: 0.0636, Accuracy: 9795/10000 (98%)
15 Test set: Avg. loss: 0.0333, Accuracy: 9888/10000 (99%)
16 Test set: Avg. loss: 0.0320, Accuracy: 9900/10000 (99%)
17 Test set: Avg. loss: 0.0360, Accuracy: 9890/10000 (99%)
18 Test set: Avg. loss: 0.0274, Accuracy: 9920/10000 (99%)
19 Test set: Avg. loss: 0.0268, Accuracy: 9925/10000 (99%)
20 Test set: Avg. loss: 0.0408, Accuracy: 9864/10000 (99%)
21 Test set: Avg. loss: 0.0298, Accuracy: 9908/10000 (99%)
22 Test set: Avg. loss: 0.0269, Accuracy: 9910/10000 (99%)
23 Test set: Avg. loss: 0.0215, Accuracy: 9922/10000 (99%)
24 Test set: Avg. loss: 0.0308, Accuracy: 9893/10000 (99%)
25 Test set: Avg. loss: 0.0317, Accuracy: 9899/10000 (99%)

SGD avec momentum
0 Test set: Avg. loss: 2.3240, Accuracy: 873/10000 (9%)
1 Test set: Avg. loss: 0.2209, Accuracy: 9403/10000 (94%)
2 Test set: Avg. loss: 0.1204, Accuracy: 9637/10000 (96%)
3 Test set: Avg. loss: 0.1056, Accuracy: 9672/10000 (97%)
4 Test set: Avg. loss: 0.0824, Accuracy: 9741/10000 (97%)
5 Test set: Avg. loss: 0.0620, Accuracy: 9795/10000 (98%)
6 Test set: Avg. loss: 0.0593, Accuracy: 9809/10000 (98%)
7 Test set: Avg. loss: 0.0663, Accuracy: 9798/10000 (98%)
8 Test set: Avg. loss: 0.0504, Accuracy: 9844/10000 (98%)
9 Test set: Avg. loss: 0.0469, Accuracy: 9839/10000 (98%)
10 Test set: Avg. loss: 0.0568, Accuracy: 9814/10000 (98%)
11 Test set: Avg. loss: 0.1389, Accuracy: 9591/10000 (96%)
12 Test set: Avg. loss: 0.0426, Accuracy: 9880/10000 (99%)
13 Test set: Avg. loss: 0.0467, Accuracy: 9823/10000 (98%)
14 Test set: Avg. loss: 0.0494, Accuracy: 9842/10000 (98%)
15 Test set: Avg. loss: 0.0507, Accuracy: 9841/10000 (98%)
16 Test set: Avg. loss: 0.0307, Accuracy: 9901/10000 (99%)
17 Test set: Avg. loss: 0.0285, Accuracy: 9906/10000 (99%)
18 Test set: Avg. loss: 0.0325, Accuracy: 9901/10000 (99%)
19 Test set: Avg. loss: 0.0302, Accuracy: 9918/10000 (99%)
20 Test set: Avg. loss: 0.0337, Accuracy: 9891/10000 (99%)
21 Test set: Avg. loss: 0.0275, Accuracy: 9919/10000 (99%)
22 Test set: Avg. loss: 0.0364, Accuracy: 9890/10000 (99%)
23 Test set: Avg. loss: 0.0349, Accuracy: 9894/10000 (99%)
24 Test set: Avg. loss: 0.0269, Accuracy: 9923/10000 (99%)
25 Test set: Avg. loss: 0.0319, Accuracy: 9893/10000 (99%)

Adaptive Gradient Descent
0 Test set: Avg. loss: 2.3113, Accuracy: 888/10000 (9%)
1 Test set: Avg. loss: 0.2555, Accuracy: 9292/10000 (93%)
2 Test set: Avg. loss: 0.1899, Accuracy: 9417/10000 (94%)
3 Test set: Avg. loss: 0.1525, Accuracy: 9536/10000 (95%)
4 Test set: Avg. loss: 0.1353, Accuracy: 9576/10000 (96%)
5 Test set: Avg. loss: 0.1192, Accuracy: 9618/10000 (96%)
6 Test set: Avg. loss: 0.1141, Accuracy: 9646/10000 (96%)
7 Test set: Avg. loss: 0.1063, Accuracy: 9661/10000 (97%)
8 Test set: Avg. loss: 0.1004, Accuracy: 9689/10000 (97%)
9 Test set: Avg. loss: 0.0956, Accuracy: 9715/10000 (97%)
10 Test set: Avg. loss: 0.0893, Accuracy: 9731/10000 (97%)
11 Test set: Avg. loss: 0.0864, Accuracy: 9731/10000 (97%)
12 Test set: Avg. loss: 0.0841, Accuracy: 9736/10000 (97%)
13 Test set: Avg. loss: 0.0809, Accuracy: 9756/10000 (98%)
14 Test set: Avg. loss: 0.0774, Accuracy: 9778/10000 (98%)
15 Test set: Avg. loss: 0.0747, Accuracy: 9780/10000 (98%)
16 Test set: Avg. loss: 0.0738, Accuracy: 9773/10000 (98%)
17 Test set: Avg. loss: 0.0700, Accuracy: 9794/10000 (98%)
18 Test set: Avg. loss: 0.0683, Accuracy: 9799/10000 (98%)
19 Test set: Avg. loss: 0.0666, Accuracy: 9801/10000 (98%)
20 Test set: Avg. loss: 0.0654, Accuracy: 9806/10000 (98%)
21 Test set: Avg. loss: 0.0656, Accuracy: 9794/10000 (98%)
22 Test set: Avg. loss: 0.0623, Accuracy: 9815/10000 (98%)
23 Test set: Avg. loss: 0.0613, Accuracy: 9810/10000 (98%)
24 Test set: Avg. loss: 0.0604, Accuracy: 9811/10000 (98%)
25 Test set: Avg. loss: 0.0586, Accuracy: 9819/10000 (98%)

RMSProp
0 Test set: Avg. loss: 2.3306, Accuracy: 823/10000 (8%)
1 Test set: Avg. loss: 0.2478, Accuracy: 9236/10000 (92%)
2 Test set: Avg. loss: 0.1666, Accuracy: 9488/10000 (95%)
3 Test set: Avg. loss: 0.1445, Accuracy: 9545/10000 (95%)
4 Test set: Avg. loss: 0.1207, Accuracy: 9620/10000 (96%)
5 Test set: Avg. loss: 0.0958, Accuracy: 9702/10000 (97%)
6 Test set: Avg. loss: 0.0796, Accuracy: 9740/10000 (97%)
7 Test set: Avg. loss: 0.0739, Accuracy: 9775/10000 (98%)
8 Test set: Avg. loss: 0.0627, Accuracy: 9811/10000 (98%)
9 Test set: Avg. loss: 0.0587, Accuracy: 9821/10000 (98%)
10 Test set: Avg. loss: 0.0532, Accuracy: 9825/10000 (98%)
11 Test set: Avg. loss: 0.0504, Accuracy: 9839/10000 (98%)
12 Test set: Avg. loss: 0.0483, Accuracy: 9837/10000 (98%)
13 Test set: Avg. loss: 0.0448, Accuracy: 9856/10000 (99%)
14 Test set: Avg. loss: 0.0427, Accuracy: 9861/10000 (99%)
15 Test set: Avg. loss: 0.0377, Accuracy: 9878/10000 (99%)
16 Test set: Avg. loss: 0.0350, Accuracy: 9893/10000 (99%)
17 Test set: Avg. loss: 0.0350, Accuracy: 9888/10000 (99%)
18 Test set: Avg. loss: 0.0300, Accuracy: 9911/10000 (99%)
19 Test set: Avg. loss: 0.0319, Accuracy: 9896/10000 (99%)
20 Test set: Avg. loss: 0.0331, Accuracy: 9892/10000 (99%)
21 Test set: Avg. loss: 0.0259, Accuracy: 9918/10000 (99%)
22 Test set: Avg. loss: 0.0256, Accuracy: 9915/10000 (99%)
23 Test set: Avg. loss: 0.0246, Accuracy: 9913/10000 (99%)
24 Test set: Avg. loss: 0.0272, Accuracy: 9913/10000 (99%)
25 Test set: Avg. loss: 0.0232, Accuracy: 9925/10000 (99%)
[562.7100427150726, 124.2383201122284, 120.02731442451477, 120.82826137542725, 119.95251798629761]
Stochastic Gradient Descent
[2.3316362548828127, 0.2210946304321289, 0.27457635192871094, 0.2427280014038086, 0.2604205047607422, 0.23319992523193359, 0.21264894104003906, 0.27741934204101565, 0.30254359436035155, 0.29524080200195313, 0.24242805938720702, 0.3674799835205078, 0.35780528564453123, 0.4305636932373047, 0.7413542297363281, 0.7133555480957031, 0.6722776611328125, 1.9791890991210936, 1.6472069946289063, 1.3821622436523437, 0.851112548828125, 0.7261248901367188, 1.0056425537109375, 1.0643390502929688, 0.5359077941894531, 0.8838520141601562] 
Mini Batch
[2.320883203125, 0.27018880615234375, 0.17302415466308593, 0.13885804595947265, 0.12115076446533203, 0.08938411712646484, 0.1166587142944336, 0.06629333305358887, 0.06031419372558594, 0.051358307647705076, 0.049393094635009765, 0.05327142524719238, 0.04537523593902588, 0.03992301864624023, 0.06360716171264648, 0.033316340446472165, 0.032047317123413084, 0.0360383243560791, 0.027380292701721192, 0.026810224914550783, 0.040767083358764646, 0.02976155204772949, 0.026921692085266114, 0.021546893215179445, 0.030810290145874022, 0.031747956848144535]
SGD avec momentum
[2.3239818115234376, 0.2209286346435547, 0.12043540725708007, 0.10564624786376953, 0.08240318641662597, 0.06201260070800781, 0.05927638511657715, 0.06629322700500488, 0.05044482879638672, 0.046931081581115724, 0.056803856658935545, 0.1389021469116211, 0.04262736434936523, 0.046695319175720215, 0.04943898124694824, 0.05072579002380371, 0.030711058616638184, 0.028460077476501464, 0.032476054573059084, 0.03018532295227051, 0.03371953887939453, 0.02747618522644043, 0.036403561210632325, 0.0349139310836792, 0.02689502477645874, 0.03193676223754883]
Adaptive Gradient Descent
[2.3112970703125, 0.25553587646484377, 0.18993792572021484, 0.15246983032226563, 0.13530175628662108, 0.11918037490844727, 0.11408133544921875, 0.10625354614257812, 0.10042412109375, 0.0955956398010254, 0.08933588638305665, 0.08636952285766601, 0.08411043739318848, 0.08085326385498047, 0.07738852081298828, 0.07470657272338867, 0.07381815452575684, 0.07003958625793456, 0.06830297775268555, 0.06659932479858398, 0.06540262794494629, 0.06559038963317872, 0.06226076469421387, 0.0612676513671875, 0.06039225730895996, 0.058605870056152344]
RMSProp
[2.33060732421875, 0.24775285034179687, 0.16660045013427735, 0.14447926940917968, 0.12067469253540039, 0.09582753677368164, 0.0796376853942871, 0.07393771018981933, 0.0626822208404541, 0.05867256622314453, 0.05322350807189941, 0.0503968376159668, 0.048264369201660155, 0.04480867519378662, 0.04272948188781738, 0.037682349395751956, 0.034982364082336424, 0.035010625267028805, 0.029999456214904786, 0.03191400318145752, 0.03311421718597412, 0.025867877388000487, 0.025623058891296388, 0.02459680528640747, 0.027172580242156984, 
0.023227395820617676]